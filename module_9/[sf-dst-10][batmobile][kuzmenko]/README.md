# 	Проект 8. Возьмёте Бэтмобиль?  

* Шаг 1. Построим «наивную» ML-модель на табличных данных, которая предсказывает цену по модели и году выпуска. Это позволит нам задать направление для дальнейших экспериментов.  
		 Впоследствии на этом этапе вы можете доработать вашу модель из проекта «Выбираем авто выгодно». 
### Точность наивной модели по метрике MAPE: 19.88% - на leaderboard не проверялось.  
------------
* Шаг 2. Обработаем и отнормируем признаки. Feature Engenearing:  
	* Связали productionDate и modelDate c 2021г. и прологарифмировали    
	* В enginePower собрали все типы двигателей, включая электро  
	* engineDisplacement - преобразовали в число 
	* km_per_year - средний пробег за год
	* km_per_year_power  - потеря мощности от пробега  
	* mileage - прологарифмировали для придания нормального распределения  
	* sell_id1 - прологарифмировали - идея в том, что косвенно указывает на момент продажи и может указать на зависимость цены от времени  
	* Численные признаки отнормируем MinMaxScaler(feature_range=(-1,1))  
	* Категориальные признаки 'bodyType', 'brand', 'color', 'fuelType', 'model_info', 'numberOfDoors', 'vehicleTransmission', 'Владельцы',  'ПТС', 'Привод', 'Руль'  
закодируем OneHotEncoding  
 * description - будем использовать в дальнейшем - анализировать текст и извлекать embedding-и  
* остальные признаки удалим  
* price прологарифмировали и сохранили в price_1 - не все модели хорошо отработали на логарифмированном price    
-----------
* Шаг 3  Сделаем первую модель на основе градиентного бустинга с помощью CatBoost.
### TEST mape: 10.99% Для примера TEST mape: 11.01% дает на leaderboard 11.89%  
-----------
* Шаг 4. Решим эту же задачу с помощью DL (модель NN Tabular) и сравним результаты.  
###TEST mape: 10.84% --- leader board 11.51713%  
-----------  
* Шаг 5. Добавим текстовые данные (NLP) и сделаем Multi-Input нейронную сеть для анализа и табличных данных, и текста одновременно.
	* Попробовалии использовать feateres полученные из BERT. Модель, поддерживающая русский язык выдает 768-и мерный вектор на документ.  
	  * Прямое использование этих feateres не дает значимого разультата.
	  * Уменьшим размерность из 768 мерного эмбеддинга создадим свои 256 представлений-категорий 
	* Обучим модель в три шага: learning rate -> 0.005, 0.0025, 0.001. 
	* Получили TEST mape: 11.25%, что несколько хуже чем предыдущие модели.  
	Предположение - в описании, по большому счету, значимой информации не много. Наблюдается "перехваленность" предложений относительно реальной цены.  Описание, скорее влияет на скорость продажи, чем на цену. 
### TEST mape: 11.25%	
-----------  
* Шаг 6. Добавим обработку изображений в Multi-Input нейронную сеть.  
	* EfficientNetB3 обученная на 'imagenet' дает хуже результат (на 0.2) чем использование тюнненной EfficientNetB5 из соревнования Ford vs Ferrary.  
	  Берем сетку полученную на соревновании Ford vs Ferrary  
	* Обучим модель в три шага: learning rate -> 0.005, 0.0025, 0.001.
	* Странно, но модель ещё ухудшилась ((( TEST mape: 11.69% --> leader board = 12.27499%
### TEST mape: 11.69% --> leader board = 12.27499%  
-----------
## На Шагах 6-7 модель не переобучалась (val loss был ниже learning loss всё время, за исключением первых эпох), значит она недообучилась. Видимо, нужно поработать с тактикой обучения - слишком сложные данные.

-----------
* Шаг 7. Осуществим ансамблирование градиентного бустинга и нейронной сети (усредним их предсказания)  
* ### Blend (CNN-табличный + BERT + EfficientNetB3) + CatBoost ) TEST mape: 10.47% -> leaderboard 10.96%  
* ### Blending CatBoost + CNN TEST mape: 10.22% -> Leader board 10.92507% что ЛУЧШЕ чем более сложная модель Blend (CNN-табличный + BERT + EfficientNetB3) + CatBoost )
## В итоге, 4-е место на kaggle
-------------  
# Дополнительно:  
* Заменим в Шаге №6 эмбеддинги, полученные из BERT модели, на эмбеддинги (50), полученные из Mystem Doc2Vec, пробросим их без изменений  	
	### Результат :
	## Без блендинга:  
		* BERT TEST mape: 11.69% --> leader board = 12.27499%
		* Mystem Doc2Vec TEST mape: 11.20% -> 11.79%
	## С блендингом: 	
		 * BERT embeddings:
			 * 10.47% --> 10.96% С помомощью тюненной сети из Ford vs Ferrary
		Mystem Doc2Vec:
			 * 10.44% --> 11.0% С помомощью тюненной сети из Ford vs Ferrary
## Модель с BERT embeddings в блендинге дает несколько лучший результат, при том, что самостоятельно работает чуть хуже. Видимо, нужна более тонкая настройка  
# Победил блендинг CatBoost + CNN

	

