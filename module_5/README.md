##  [SF-DST]Проект 5. Выбираем авто выгодно  
Предсказание цены автомобиля  
sf-dst-10-car-price-prediction-kuzmenko-10.71896.ipynb kaggle score = 10.71896  
Выводы:  
1. Получен результат на Kaggle 10.71896%.  
2. Результат адекватен постановке задачи ( на 3+ балла), с учетом:    
	- Данные, доступные для парсинга актуальны на сентябрь 2020  
	- Тестовые данные, видимо, относятся к периоду на 6-7 месяцев ранее    
	- Разница цен за обозначенный период составила порядка 9-12%, НО на разные группы автомобилей %% разный (это учесть не удалось)    
	- Предпринята попытка анализа текстовой информации с использованием nltk (DOC2VEC + lda model) - в результате получилось 7 значимых фич:    
		- 3 темы по отзывам - lda model  
		- метка кластера по эти группам  
		- метка кластера полученная из описания - модель DOC2VEC  
		- cosine рассотяние между средним значением эмбеддингов текстов от диллеров до эмбеддингов каждого объявления  
		- флаг диллерское объявление или нет - использовал простой порог, наверное нужно было использовать логистический сигиоид).  
		- НО тема для глубокого понимания не раскрыта...     	
3. 	Stacking xgboost, lightgbm, catboost -> xgboost VS catboost - результатов не дал. Один catboost == 10.71896, Stacking 11.58573%  Возможно, не подобрал гипер-параметры, особено lightgbm ((   
4.  Прирост точности за счет использованиея nltk врядли компенсирует потерю в скорости рабоы модели - около +1% в точности  и +200% ко времени обучение и +100% ко времени предсказание  
5.  "Нужно больше золота" - для улучшения результата нужны ещё данные, причем и в тестовой выборке, например, инфорамация о првреждениях АМ, более полная инф-я о сроках владения каждым владельцем  


Файлы:  
1. 04-09-2020/car_links_cars_04.txt  - ссылки на АМ для парсинга  
2. dillers/dillers_txt.csv - примеры текстов диллеров, из них получаем усредненный эмбеддинг для последующего вычисления "похожести" описания на диллерский текст  
3. \langdata:  -- языковые модели nltk - если не зафиксировать модель, даже при задании random seed получаются немного разные результаты  ??????
	DOC2VEC_model.model  
	lda_model.model  
	lda_model.model.expElogbeta.npy  
	lda_model.model.id2word  
	lda_model.model.state  
4. parseautoru/[SF-DST-10] [Car Price prediction] [Kuzmenko] -parse auto_ru - скрипт асинхронного парсинга с динамическим кэшированием proxy  
5. submission_blend_v37-10.71896.csv - результат на Kaggle БЕЗ Stacking!!! 
6. sf-dst-10-car-price-prediction-kuzmenko_stacking.ipynb - скрипт Stacking
	
	

 
	

