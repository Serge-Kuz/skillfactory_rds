# Проект  Ford vs Ferrari: определяем модель авто по фото.

## В проекте были применены следующие техники:
* В качестве базовой архитектуры выбрана EfficientNet B5. Выбор был в надежде, что заметно меньший размер (2.5 раза по сравнению с B7)\  
  сети при несколько меньшей точности (~1.5%) даст возможность работать на большем разрешении\  
  и применять модель на мобильных устройствах средней производительности, а так же развертывать легкие микро-сервисы (в т.ч. на бесплатных ресурсах).   
* В качестве весов инициализации базовой модели были выбраны предобученные по технологии "Noisy student" веса.
* Была выбрана реализация EfficientNetB5 из Keras\
  Особенностью данной реализации является подача в модель RGB 8bit изображений - нормализация проводится в самой модели.
  Ещё одной особенностью данной архитектуры является её блочное построение, что в случае fine-tuning требует "замораживать" уровни строго блоками целеком.  
* Применялся transfer learning с "новой головой" достаточно простой структуры. В качестве регуляризации использовались BatchNormalization и сильный Dropout(0.5)
* Применялся fine-tuning с заморозкой примерно половины нижних (начальных) уровней сети,    
  при этом BatchNormalization уровни в "размороженной" части оставались замороженными, что давало большую скорость обучения.    
  Обучение 100% сети не дало результата. Это поведение было описано в документации. 
* Применялись различные LR на разных шагах - чем этап глубже, тем ниже LR
* optimizer ADAM показал лучшую сходимость, RMSprop не рекомендуется использовать при fine-tuning EfficientNet
* Loss - categorical_crossentropy
* Pазмер изображения должен быть кратен 8 и 16, использовались 2 разрешения: 224dpi и 456dpi.  
    Transfer learning и основной fine-tuning проводились на разрешении 224dpi     
    Последний шаг дообучения на разрешении 456dpi (4 эпохи)
* Размер батча уменьшался с каждым шагом, что давало лучшую сходимость на тестовых данных (хотя памяти GPU было достаточно), но увеличивало время вычисления эпохи  
* Применялись функции callback ModelCheckpoint, EarlyStopping, ReduceLROnPlateau  
* Применение TTA (Test Time Augmentation) не дало прироста точности
* Возможностей Keras по аугментации было достаточно.  
  Подбор более продвинутх библиотек аугментации изображений слишком долог по времени (жалко тратить 40 часов лимита GPU)   
  и на представленных изображениях врядли даст прирост.  
  Возможно, из продвинутых техник было бы полезно применить [CLAHE (Contrast Limited Adaptive Histogram Equalization)](https://docs.opencv.org/master/d5/daf/tutorial_py_histogram_equalization.html) и  
  [Адаптивную гамма коррекцию](https://jivp-eurasipjournals.springeropen.com/articles/10.1186/s13640-016-0138-1)  
  Применение данных алгоритмов в обработке фотографий для последующей печати дает отличный результат. Должно и здесь сработать.  
  

# Выводы:
* Выбор в качестве базовой архитектуры выбрана EfficientNet B5 был оправдан:
    Модель настроенная на разрешение 456dpi дала результат 0.97213 при лучшем результате на leaderboard 0.98292 :)
    Размер файла модели (456dpi) 340Mb - что НЕ сравнимо с B7 НО при 224dpi (741.53Mb)   
    что дает возможность:
		* при несколько меньшей точности (~1.0%) на большем разрешении (разница в детализации 224dpi vs 456dpi огромна) и downsapling в меньшее разрешение - процесс с сильными потерями информации, к тому же не быстрый.    
		* применять модель на мобильных устройствах средней производительности,  
		* развертывать легкие микро-сервисы (в т.ч. на бесплатных ресурсах).   
* Были получены и закреплены практические + теоретические навыки
* Попытка сначала провести transfer learning + fine-tuning на модели EfficientNet B5 по Stanford Cars Dataset, а затем использовать полученную модель в соревновании  - требует дальнейшей проработки:     
       1. Не нужна нормализация - она выполняестя в самой модели, причем эту практику крайне рекоммендуют.  
	   2. Обкропил картинки по координатам в датасете, добавил random crop и конечно,  
	      всякая аугментация (не продвинутая, хотел использовать CLAHE - но это выполняется на CPU и долго (( ).  
	   3. Нашел описание  "модель астомобиля"->"номера изображений". Собрал похожие в категории, например, BMW и BMW SUV. Получилось 49 категорий vs 196 как в исходном датасете.  	   
	   5. Стратифицировал разделение
 На этапе обучения только классификатора, получилось val_loss: 1.5944 - val_accuracy: 0.5206.    
 Уже видно, что можно не учить дальше классификатор, а fine-tune-ить модель, и затем её использовать как базу для соревнования (фичи автомобилей должны быть отличными) - должна догнать лучишие результаты B7    
 
## Файлы моделей:
   ### efficientnetb5_notop.h5 - EfficientNet B5 "Noisy student" веса    
   ### best_model_50perc_st2.hdf5 - Заморожено до block5a   
   ### best_model_456.hdf5 - обучена на разрешении 456dpi  
